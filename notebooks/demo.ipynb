{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udf31 RAG Chatbot Demo Notebook\n", "\u672c Notebook \u5c55\u793a\u5982\u4f55\uff1a\n", "- \u4e0a\u50b3\u8207\u89e3\u6790 PDF / PPT / \u5716\u7247\u6587\u4ef6\n", "- \u5efa\u7acb\u5411\u91cf\u5eab\u4e26\u67e5\u8a62\u8a9e\u610f\u6bb5\u843d\n", "- \u547c\u53eb OpenAI GPT \u56de\u7b54\u554f\u984c\n", "- \u986f\u793a\u5f15\u7528\u4f86\u6e90\u8207 token \u4f7f\u7528\u7d71\u8a08\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# \u521d\u59cb\u5316\uff1a\u8f09\u5165\u6a21\u7d44\u8207\u6a21\u578b\n", "from sentence_transformers import SentenceTransformer\n", "import faiss, numpy as np, openai\n", "from app.config import *\n", "from app.loader import load_document_text\n", "from app.sensitive import contains_sensitive\n", "from pprint import pprint\n", "\n", "openai.api_key = OPENAI_API_KEY\n", "model = SentenceTransformer(EMBEDDING_MODEL)\n", "index = faiss.IndexFlatL2(model.get_sentence_embedding_dimension())\n", "chunks, meta = [], []"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# \u4e0a\u50b3\u4e26\u8655\u7406\u6587\u4ef6\uff08PDF / PPT / \u5716\u7247\uff09\n", "file_path = \"../data/documents/demo.pdf\"  # \u66ff\u63db\u70ba\u4f60\u81ea\u5df1\u7684\u6a94\u6848\n", "text = load_document_text(file_path)\n", "\n", "def split_and_embed(text, filename):\n", "    lines = text.split(\"\\n\")\n", "    current = \"\"\n", "    for i, line in enumerate(lines):\n", "        if len(current) + len(line) < CHUNK_SIZE:\n", "            current += line.strip() + \" \"\n", "        else:\n", "            chunks.append(current.strip())\n", "            meta.append({\"source\": filename, \"position\": f\"\u7b2c{i+1}\u884c\u9644\u8fd1\"})\n", "            current = line.strip() + \" \"\n", "    if current:\n", "        chunks.append(current.strip())\n", "        meta.append({\"source\": filename, \"position\": \"\u7d50\u5c3e\"})\n", "    vecs = model.encode(chunks[-len(meta):])\n", "    index.add(np.array(vecs))\n", "\n", "split_and_embed(text, \"demo.pdf\")\n", "print(f\"\u5411\u91cf\u6578\u91cf\uff1a{index.ntotal}\")"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# \u8f38\u5165\u554f\u984c\u4e26\u67e5\u8a62\u76f8\u4f3c\u6bb5\u843d\n", "query = \"SBTi \u76ee\u6a19\u70ba\u4f55\u9078\u64c7 near-term \u800c\u4e0d\u662f net-zero\uff1f\"\n", "qvec = model.encode([query])\n", "D, I = index.search(np.array(qvec), 3)\n", "top_chunks = [chunks[i] for i in I[0]]\n", "references = [meta[i] for i in I[0]]\n", "\n", "print(\"\\n\\n\u3010\u76f8\u95dc\u6bb5\u843d\u3011\")\n", "for i, (chunk, ref) in enumerate(zip(top_chunks, references)):\n", "    print(f\"\\n--- Top {i+1} ---\\n{chunk[:300]}...\\n\u4f86\u6e90\uff1a{ref['source']}\uff08{ref['position']}\uff09\")"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# \u547c\u53eb OpenAI GPT \u56de\u7b54\u554f\u984c\u4e26\u986f\u793a token \u4f7f\u7528\u60c5\u6cc1\n", "if USE_OPENAI:\n", "    prompt = (\"\u6839\u64da\u4ee5\u4e0b\u5167\u5bb9\u56de\u7b54\u554f\u984c\uff1a\\n\" + \"\\n---\\n\".join(top_chunks) + f\"\\n\\n\u554f\u984c\uff1a{query}\")\n", "    response = openai.ChatCompletion.create(\n", "        model=OPENAI_MODEL,\n", "        messages=[\n", "            {\"role\": \"system\", \"content\": \"\u4f60\u662f\u5c08\u696d\u6c38\u7e8c\u9867\u554f\uff0c\u8acb\u6839\u64da\u8cc7\u6599\u56de\u7b54\u554f\u984c\u3002\"},\n", "            {\"role\": \"user\", \"content\": prompt}\n", "        ]\n", "    )\n", "    answer = response.choices[0].message.content.strip()\n", "    usage = response.usage\n", "\n", "    print(\"\\n\u3010GPT \u56de\u7b54\u3011\\n\", answer)\n", "    print(\"\\n\ud83d\udcce \u5f15\u7528\u4f86\u6e90\uff1a\")\n", "    for r in references:\n", "        print(f\"- {r['source']}\uff08{r['position']}\uff09\")\n", "    print(\"\\n\ud83d\udcca Token \u4f7f\u7528\uff1a\")\n", "    pprint(dict(usage))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": ""}}, "nbformat": 4, "nbformat_minor": 2}